console.log("üìú content.js loaded");

// ===============================
// Highlighting & Reading functions
// ===============================
let utterance;
let textNodes = [];
let currentNodeIndex = 0;
let reading = false;
let paused = false;
let lastHighlight = null;

function highlightNode(node) {
  // Remove previous highlight
  if (lastHighlight) {
    const parent = lastHighlight.parentNode;
    if (parent)
      parent.replaceChild(
        document.createTextNode(lastHighlight.textContent),
        lastHighlight
      );
    lastHighlight = null;
  }

  if (!node?.parentNode) return node;
  const span = document.createElement("span");
  span.style.backgroundColor = "#ffeb3b80";
  span.style.borderRadius = "3px";
  span.textContent = node.nodeValue;
  node.parentNode.replaceChild(span, node);
  lastHighlight = span;
  return span;
}

// Improve getVisibleTextNodes() to skip ads and popups
function getVisibleTextNodes() {
  const walker = document.createTreeWalker(
    document.body,
    NodeFilter.SHOW_TEXT,
    {
      acceptNode(node) {
        const text = node.nodeValue.trim();
        if (!text) return NodeFilter.FILTER_REJECT;

        const el = node.parentElement;
        if (!el) return NodeFilter.FILTER_REJECT;

        const tag = el.tagName.toLowerCase();
        if (
          [
            "script",
            "style",
            "img",
            "video",
            "svg",
            "noscript",
            "iframe",
          ].includes(tag)
        )
          return NodeFilter.FILTER_REJECT;

        // Skip hidden elements or likely ads/popups
        const style = getComputedStyle(el);
        if (style.display === "none" || style.visibility === "hidden")
          return NodeFilter.FILTER_REJECT;
        if (
          el.closest(
            'header, footer, nav, aside, [role="banner"], [role="alert"], [aria-modal="true"]'
          )
        )
          return NodeFilter.FILTER_REJECT;
        if (!el.innerText || el.innerText.length < 5)
          return NodeFilter.FILTER_REJECT;

        if (el.innerText.length < 5) return NodeFilter.FILTER_REJECT; // skip tiny UI text
        return NodeFilter.FILTER_ACCEPT;
      },
    }
  );
  const nodes = [];
  while (walker.nextNode()) nodes.push(walker.currentNode);
  return nodes;
}

async function startReading() {
  // Resume from pause
  if (paused) {
    console.log("‚ñ∂Ô∏è Resuming reading from index", currentNodeIndex);
    paused = false;
    reading = true;
    continueReading(); // üîÅ call the loop again
    return;
  }

  // Start fresh
  if (!reading) {
    textNodes = getVisibleTextNodes();
    if (!textNodes.length) return alert("No readable text found.");
    reading = true;
    paused = false;
    currentNodeIndex = 0;
    continueReading(); // start loop
  }
}

async function continueReading() {
  console.log(
    `Continuing from node ${currentNodeIndex}/${textNodes.length}`
  );

  for (let i = currentNodeIndex; i < textNodes.length && reading; i++) {
    if (paused) break; // stop immediately if paused
    const node = textNodes[i];
    if (!node) continue; // safety guard if node was removed

    const span = highlightNode(node);
    if (!span) continue;

    utterance = new SpeechSynthesisUtterance(span.textContent);
    const { userLanguage } = await chrome.storage.sync.get("userLanguage");
    utterance.lang = userLanguage || "en";

    await new Promise((resolve) => {
      utterance.onend = () => {
        // Double-check span still exists before changing its style
        if (span && span.style) {
          span.style.backgroundColor = "transparent";
        }
        currentNodeIndex = i + 1; // remember where we stopped
        resolve();
      };

      utterance.onerror = (err) => {
        console.error("Speech error:", err);
        resolve(); // continue with next node
      };

      try {
        window.speechSynthesis.speak(utterance);
      } catch (err) {
        console.error("üéôÔ∏è Speak failed:", err);
        resolve();
      }
    });
  }

  if (!paused) {
    console.log("üèÅ Finished reading all text");
    reading = false;
    currentNodeIndex = 0;
  }
}

function pauseReading() {
  if (!reading) return;
  paused = true;
  console.log("‚è∏Ô∏è Paused at index", currentNodeIndex);
  window.speechSynthesis.cancel(); // cancel current utterance
}

function stopReading() {
  if (!reading) return;
  reading = false;
  paused = false;
  currentNodeIndex = 0;
  console.log("Reading stopped completely");
  window.speechSynthesis.cancel();
}
// =======================================
// Handle messages from popup or background
// =======================================
chrome.runtime.onMessage.addListener(async (req) => {
  const { userLanguage } = await chrome.storage.sync.get("userLanguage");
  if (req.action === "read_text") startReading();
  if (req.action === "pause_read") pauseReading();
  if (req.action === "stop_read") stopReading();
  if (req.action === "translate_page") translatePage();


  if (req.action === "show_commands") {
    const text = getCommandsText(userLanguage);
    window.voxmateOverlay.showCommands(text);
  }

  if (req.action === "ask_command") {
    const { question } = req;
    if (!question) return;
    console.log("üí¨ User asked:", question);
    handleAskCommand(question);
  }

  if (req.action === "summarise_page") {
    handleSummarisePage();
  }

  // if (req.action === "show_summary") {
  //   const summary = req.summary || "No summary available.";
  //   window.voxmateOverlay.showInfo(summary, "Page Summary");
  // }
});

// =======================================
// TranslatePage
// =======================================
async function translatePage() {
  const loadingId = 'translate_' + Date.now();

  try {
    console.log("‚öôÔ∏è Starting page translation...");
    window.voxmateOverlay.showLoading(
      "Translating page content...",
      "Translation in Progress",
      loadingId
    );

    const bodyText = document.body.innerText.slice(0, 20000);

    return new Promise((resolve) => {
      chrome.runtime.sendMessage(
        { action: "translate_auto", text: bodyText },
        (response) => {
          if (!response?.success) {
            console.error("‚ùå Translation failed:", response?.error);
            window.voxmateOverlay.removeLoading(loadingId);
            window.voxmateOverlay.showError(
              `Translation failed: ${response?.error || 'Unknown error'}`,
              "Translation Error"
            );
            resolve(false);
            return;
          }

          try {
            const translatedText = response.result;
            const walker = document.createTreeWalker(
              document.body,
              NodeFilter.SHOW_TEXT
            );
            const translatedWords = translatedText.split(/\s+/);
            let index = 0;

            while (walker.nextNode()) {
              const node = walker.currentNode;
              const words = node.nodeValue.trim().split(/\s+/);
              if (words.length > 2) {
                node.nodeValue = translatedWords
                  .slice(index, index + words.length)
                  .join(" ");
                index += words.length;
              }
            }

            window.voxmateOverlay.removeLoading(loadingId);
            window.voxmateOverlay.showSuccess(
              "Page translation completed successfully!",
              "Translation Complete"
            );
            resolve(true);
          } catch (error) {
            console.error("‚ùå Error applying translation:", error);
            window.voxmateOverlay.removeLoading(loadingId);
            window.voxmateOverlay.showError(
              "Error applying translation to page",
              "Application Error"
            );
            resolve(false);
          }
        }
      );
    });
  } catch (error) {
    console.error("‚ùå Error in translatePage:", error);
    window.voxmateOverlay.removeLoading(loadingId);
    window.voxmateOverlay.showError(
      "Failed to start translation process",
      "Process Error"
    );
    return false;
  }
}


// -------------------------------
// Local command mapper (returns same object shape as Gemini mapping)
// -------------------------------
function mapLocalCommand(rawText, userLang = "en") {
  const raw = String(rawText || "").trim();
  const rawLC = raw.toLowerCase();

  // Phrase maps per language (you can expand)
  const maps = {
    en: {
      read: ["read", "start reading", "read page", "read this"],
      pause: ["pause", "hold on", "wait"],
      stop: ["stop", "cancel", "end reading", "stop reading"],
      translate: ["translate", "translate page", "translate this"],
      "show commands": ["show commands", "commands", "help", "what can you say", "what can i say"],
      summarise: ["summarise", "summarize", "summary", "summarize this", "summarise this"],
    },
    hi: {
      read: ["‡§™‡§¢‡§º‡•ã", "‡§™‡•ù‡•ã"],
      pause: ["‡§∞‡•Å‡§ï‡•ã", "‡§†‡§π‡§∞‡•ã"],
      stop: ["‡§¨‡§Ç‡§¶ ‡§ï‡§∞‡•ã", "‡§∞‡•ã‡§ï ‡§¶‡•ã"],
      translate: ["‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶", "‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶ ‡§ï‡§∞‡•ã", "‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶ ‡§ï‡§∞‡•ã ‡§™‡•á‡§ú"],
      "show commands": ["‡§ï‡§Æ‡§æ‡§Ç‡§° ‡§¶‡§ø‡§ñ‡§æ‡§ì", "‡§ï‡§Æ‡§æ‡§Ç‡§°", "‡§∏‡§π‡§æ‡§Ø‡§§‡§æ", "help"],
      summarise: ["‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂", "‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂ ‡§¨‡§®‡§æ‡§ì"],
    },
    zh: {
      read: ["ËØª", "ÊúóËØª"],
      pause: ["ÊöÇÂÅú"],
      stop: ["ÂÅúÊ≠¢"],
      translate: ["ÁøªËØë"],
      "show commands": ["ÊòæÁ§∫ÂëΩ‰ª§", "ÂëΩ‰ª§", "Â∏ÆÂä©"],
      summarise: ["ÊÄªÁªì"],
    },
    es: {
      read: ["leer"],
      pause: ["pausa"],
      stop: ["detener"],
      translate: ["traducir"],
      "show commands": ["comandos", "mostrar comandos", "ayuda"],
      summarise: ["resumir"],
    },
    fr: {
      read: ["lire"],
      pause: ["pause"],
      stop: ["arr√™ter", "stop"],
      translate: ["traduire"],
      "show commands": ["commandes", "afficher les commandes", "aide"],
      summarise: ["r√©sumer"],
    }
  };

  // Use userLang map AND english map (english always included)
  const primaryMap = maps[userLang] || {};
  const englishMap = maps["en"];

  // helper to test if any phrase matches (word boundary-ish)
  const phraseMatches = (phrase) => {
    const p = phrase.toLowerCase();
    // match whole words or common multiword phrases
    return rawLC.includes(` ${p}`) || rawLC.startsWith(p) || rawLC.endsWith(p) || rawLC === p || rawLC.includes(p + " ");
  };

  // check primaryLang first
  for (const [cmd, phrases] of Object.entries(primaryMap)) {
    if (phrases.some(phraseMatches)) {
      // If command is 'ask' like question? handled below
      if (cmd === "show commands") {
        return [{ command: "show commands", raw }];
      }
      if (cmd === "summarise") {
        return [{ command: "summarise", raw }];
      }
      return [{ command: cmd, raw }];
    }
  }

  // always also check English map
  for (const [cmd, phrases] of Object.entries(englishMap)) {
    if (phrases.some(phraseMatches)) {
      if (cmd === "show commands") {
        return [{ command: "show commands", raw }];
      }
      if (cmd === "summarise") {
        return [{ command: "summarise", raw }];
      }
      return [{ command: cmd, raw }];
    }
  }

  // If the utterance *looks* like a question -> treat as ask
  if (/^(what|who|how|when|why|where|which|is|are)\b/i.test(rawLC) || rawLC.endsWith("?")) {
    return [{ command: "ask", question: raw, raw }];
  }

  // Some natural "ask" phrases in other languages
  if (/(ask|tell me|explain|define|‡§¨‡§§‡§æ‡§ì|‡§¨‡§§‡§æ‡§á‡§è|ËØ∑ÈóÆ|ËØ∑ÂëäËØâÊàë|‡§™‡•Å‡§õ‡•ã)/i.test(raw)) {
    // extract probable question part (naive)
    const q = raw.replace(/^(ask|tell me|explain|define)\s*/i, "").trim();
    return [{ command: "ask", question: q || raw, raw }];
  }

  // No confident local mapping
  return [{ command: "unknown", raw }];
}

// -------------------------------
// Robust speakCommands (async) - fixes chrome.storage usage and string checks
// -------------------------------
async function speakCommands(text) {
  try {
    window.speechSynthesis.cancel();

    const title = text?.title ? String(text.title) : "Commands";
    const commandsList = Array.isArray(text?.commands) ? text.commands.join(". ") : String(text?.commands || "");

    const { userLanguage } = await chrome.storage.sync.get("userLanguage");
    const lang = userLanguage || "en";

    const utter = new SpeechSynthesisUtterance(`${title}. ${commandsList}`);
    utter.lang = (lang === "en" ? "en-US" : (lang === "zh" ? "zh-CN" : lang));
    utter.onend = () => console.log("‚úÖ Finished speaking commands");
    utter.onerror = (err) => {
      console.error("üîä speakCommands error:", err);
      if (err && err.error === "not-allowed") {
        console.warn("üîá Speech blocked. Ensure the page had a user gesture to enable audio.");
      }
    };

    window.speechSynthesis.speak(utter);
  } catch (e) {
    console.error("‚ùå speakCommands failed:", e);
  }
}

function getCommandsText(lang) {
  const translations = {
    en: {
      title: "üéôÔ∏è Voice Commands",
      commands: [
        "Say 'read'",
        "Say 'pause'",
        "Say 'stop'",
        "Say 'translate'",
        "Say 'show commands'",
      ],
    },
    zh: {
      title: "üéôÔ∏è ËØ≠Èü≥ÂëΩ‰ª§",
      commands: ["ËØ¥‚ÄúËØª‚Äù", "ËØ¥‚ÄúÊöÇÂÅú‚Äù", "ËØ¥‚ÄúÂÅúÊ≠¢‚Äù", "ËØ¥‚ÄúÁøªËØë‚Äù", "ËØ¥‚ÄúÊòæÁ§∫ÂëΩ‰ª§‚Äù"],
    },
    hi: {
      title: "üéôÔ∏è ‡§µ‡•â‡§Ø‡§∏ ‡§ï‡§Æ‡§æ‡§Ç‡§°‡•ç‡§∏",
      commands: [
        "'‡§™‡§¢‡§º‡•ã' ‡§ï‡§π‡•á‡§Ç",
        "'‡§∞‡•Å‡§ï‡•ã' ‡§ï‡§π‡•á‡§Ç",
        "'‡§¨‡§Ç‡§¶ ‡§ï‡§∞‡•ã' ‡§ï‡§π‡•á‡§Ç",
        "'‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶ ‡§ï‡§∞‡•ã' ‡§ï‡§π‡•á‡§Ç",
        "'‡§ï‡§Æ‡§æ‡§Ç‡§° ‡§¶‡§ø‡§ñ‡§æ‡§ì' ‡§ï‡§π‡•á‡§Ç",
      ],
    },
    es: {
      title: "üéôÔ∏è Comandos de voz",
      commands: [
        "Di 'leer'",
        "Di 'pausa'",
        "Di 'detener'",
        "Di 'traducir'",
        "Di 'mostrar comandos'",
      ],
    },
    fr: {
      title: "üéôÔ∏è Commandes vocales",
      commands: [
        "Dites 'lire'",
        "Dites 'pause'",
        "Dites 'arr√™ter'",
        "Dites 'traduire'",
        "Dites 'afficher les commandes'",
      ],
    },

  };

  return translations[lang] || translations.en;
}

// =======================================
// Handle voice Input
// =======================================
let recognition;
let voiceActive = false;

function initVoiceRecognition() {
  if (!("webkitSpeechRecognition" in window)) {
    console.error("‚ùå Speech Recognition not supported.");
    return;
  }

  recognition = new webkitSpeechRecognition();

  // set language based on user preference where possible (fallback to en-US)
  chrome.storage.sync.get("userLanguage", ({ userLanguage }) => {
    const lang = userLanguage || "en";
    // Map small codes to speech recognition locales
    const recognitionLangMap = {
      en: "en-US",
      hi: "hi-IN",
      zh: "zh-CN",
      es: "es-ES",
      fr: "fr-FR",
    };
    recognition.lang = recognitionLangMap[lang] || "en-US";
    recognition.continuous = true;
    recognition.interimResults = false;

    recognition.onresult = async (event) => {
      const rawCommand = event.results[event.results.length - 1][0].transcript.trim();
      console.log("üéôÔ∏è Voice command:", rawCommand);
      window.voxmateOverlay.showInfo(`Heard: "${rawCommand}"`, "Voice Command", { duration: 3000 });

      const { userLanguage } = await chrome.storage.sync.get("userLanguage");
      const lang = userLanguage || "en";

      // 1) Try local/direct mapping (primary language + english)
      let commandObjects = mapLocalCommand(rawCommand, lang);
      console.log("üîé Local mapping result:", commandObjects);

      // 2) If local mapping returns unknown -> fallback to Gemini mapping
      if (!commandObjects || (commandObjects.length === 1 && commandObjects[0].command === "unknown")) {
        try {
          console.log("‚û°Ô∏è Fallback to Gemini mapping...");
          const geminiResult = await translateCommandText(rawCommand, lang);
          // translateCommandText in your code returns an array or single object. Normalize:
          if (Array.isArray(geminiResult) && geminiResult.length) {
            commandObjects = geminiResult;
          } else if (geminiResult && geminiResult.command) {
            commandObjects = [geminiResult];
          } else {
            commandObjects = [{ command: "unknown", raw: rawCommand }];
          }
        } catch (err) {
          console.warn("‚ö†Ô∏è Gemini mapping failed, continuing with unknown:", err);
          commandObjects = [{ command: "unknown", raw: rawCommand }];
        }
      }

      // 3) Execute pipeline for each mapped object
      commandObjects.forEach(({ command, question, raw }) => {
        console.log(`‚öôÔ∏è Executing command: ${command}`, question ? `(Question: ${question})` : "");

        switch (command) {
          case "read":
            startReading();
            break;
          case "pause":
            pauseReading();
            break;
          case "stop":
            stopReading();
            break;
          case "translate":
            translatePage();
            break;
          case "show commands":
            const text = getCommandsText(userLanguage);
            window.voxmateOverlay.showCommands(text);
            speakCommands(text);
            break;
          case "summarise":
            console.log("üìù Trigger summarise function");
            handleSummarisePage().then((summary) => {
              if (summary) {
                console.log("üß† Summary ready:", summary);
                speakAnswer(summary);
              }
            });
            break;
          case "ask":
            console.log("üí¨ User asked:", question || raw);
            // handleAskCommand returns the answer; ensure speaking from voice context
            handleAskCommand(question || raw).then((answer) => {
              if (answer && voiceActive) {
                console.log("üîä Speaking from voice recognition context...");
                speakAnswer(answer);
              }
            });
            break;
          default:
            console.log("ü§∑ Unknown command, ignoring:", raw);
            break;
        }
      });
    };

    recognition.onerror = (e) => console.error("üéôÔ∏è Recognition error:", e.error);
    recognition.onend = () => {
      if (voiceActive) recognition.start(); // keep alive
    };

    recognition.start();
    voiceActive = true;
    console.log("üéß Voice recognition started (lang:", recognition.lang, ")");
  });
}

function stopVoiceRecognition() {
  if (recognition) {
    recognition.stop();
    recognition = null;
    voiceActive = false;
    console.log("Voice recognition stopped");
  }
}

chrome.runtime.onMessage.addListener((msg) => {
  if (msg.action === "toggle_voice") {
    voiceActive ? stopVoiceRecognition() : initVoiceRecognition();
  }
});


async function translateCommandText(text, userLanguage = "en") {
  console.log("üéß Sending command to background for Gemini translation...");

  return new Promise((resolve) => {
    chrome.runtime.sendMessage(
      {
        action: "translate_with_gemini",
        text,
        userLanguage,
      },
      (response) => {
        if (chrome.runtime.lastError) {
          console.error("‚ùå Message error:", chrome.runtime.lastError.message);
          resolve([{ command: "unknown", raw: text }]);
          return;
        }

        if (!response?.success) {
          console.warn("‚ö†Ô∏è Gemini translation failed:", response?.reason || response?.error);
          resolve([{ command: "unknown", raw: text }]);
          return;
        }

        const result = response.result;
        console.log("üåç Gemini interpreted command object:", result);

        if (result?.command) {
          resolve([result]); // structured [{ command, question? }]
        } else {
          resolve([{ command: "unknown", raw: text }]);
        }
      }
    );
  });
}


let geminiReady = false;

async function initGeminiAfterGesture() {
  console.log("üöÄ Checking Gemini availability...");

  try {
    const response = await chrome.runtime.sendMessage({
      action: 'checkGemini'
    });

    console.log("üì¨ Gemini check result:", response);

    if (response.success) {
      geminiReady = true;
      console.log("‚úÖ Gemini Nano is ready!");
      console.log("   Availability:", response.availability);
      hideCommandsOverlay();

      // Now you can send prompts
      // await sendPrompt("Your prompt here");
    } else {
      console.error("‚ùå Gemini not available:", response.reason);
      showGeminiStatusOverlay({
        title: "‚ö†Ô∏è Gemini Nano Unavailable",
        commands: [
          `Status: ${response.reason}`,
          response.availability ? `Availability: ${response.availability}` : '',
          response.debug ? `Debug: ${JSON.stringify(response.debug)}` : '',
          "Check chrome://on-device-internals for model status"
        ].filter(Boolean)
      });
    }
  } catch (error) {
    console.error("‚ùå Error:", error);
    showGeminiStatusOverlay({
      title: "‚ö†Ô∏è Extension Error",
      commands: [
        error.message,
        "Try reloading the extension"
      ]
    });
  }
}

// Function to send a prompt to Gemini
async function sendPrompt(prompt) {
  try {
    console.log("üì§ Sending prompt:", prompt);

    const response = await chrome.runtime.sendMessage({
      action: 'prompt',
      prompt: prompt
    });

    if (response.success) {
      console.log("üì• Response:", response.result);
      return response.result;
    } else {
      console.error("‚ùå Prompt failed:", response.error);
      return null;
    }
  } catch (error) {
    console.error("‚ùå Error sending prompt:", error);
    return null;
  }
}

// Setup gesture listener
function setupUserGestureForGemini() {
  console.log("üéØ Waiting for user gesture...");
  const gestureEvents = ["click", "keydown", "touchstart"];

  const gestureHandler = async () => {
    console.log("üëÜ User gesture detected!");
    await initGeminiAfterGesture();

    gestureEvents.forEach((evt) =>
      document.removeEventListener(evt, gestureHandler)
    );
  };

  gestureEvents.forEach((evt) =>
    document.addEventListener(evt, gestureHandler, { once: true })
  );
}

// UI Helper functions
function showGeminiStatusOverlay(config) {
  console.log("üì¢", config.title);
  config.commands.forEach(cmd => console.log("  -", cmd));
  // TODO: Implement your actual UI overlay here
}

function hideCommandsOverlay() {
  console.log("‚úì Overlay hidden");
  // TODO: Implement your actual UI overlay hiding here
}

// Initialize
console.log("üìú Gemini content script loaded");
setupUserGestureForGemini();

showGeminiStatusOverlay({
  title: "‚ö†Ô∏è Gemini Nano requires interaction",
  commands: ["Click anywhere on the page to activate AI features."]
});

// Export for use in other parts of your extension
window.geminiAPI = {
  isReady: () => geminiReady,
  sendPrompt: sendPrompt
};


async function handleAskCommand(question) {
  const loadingId = 'ask_' + Date.now();

  try {
    console.log("üí¨ Asking Gemini:", question);
    window.voxmateOverlay.showLoading(
      "Analyzing page content and finding the best answer...",
      "Finding Answer",
      loadingId
    );

    return new Promise((resolve) => {
      chrome.runtime.sendMessage(
        { action: "ask_with_gemini", question },
        (response) => {
          if (chrome.runtime.lastError) {
            console.error("‚ùå Ask message error:", chrome.runtime.lastError.message);
            window.voxmateOverlay.removeLoading(loadingId);
            window.voxmateOverlay.showError(
              "Gemini service is currently unavailable. Please try again later.",
              "Service Unavailable"
            );
            resolve(null);
            return;
          }

          if (!response?.success) {
            console.warn("‚ö†Ô∏è Ask failed:", response?.reason || response?.error);
            window.voxmateOverlay.removeLoading(loadingId);
            window.voxmateOverlay.showWarning(
              "I couldn't find a clear answer to your question in the page content.",
              "Answer Not Found"
            );
            resolve(null);
            return;
          }

          const answer = response.answer?.trim() || "No clear answer found in the page content.";
          console.log("üß† Gemini Answer:", answer);

          window.voxmateOverlay.removeLoading(loadingId);
          window.voxmateOverlay.showInfo(answer, "Answer");

          if (answer && voiceActive) {
            console.log("üîä Speaking the answer...");
            speakAnswer(answer);
          }

          resolve(answer);
        }
      );
    });
  } catch (error) {
    console.error("‚ùå Error in handleAskCommand:", error);
    window.voxmateOverlay.removeLoading(loadingId);
    window.voxmateOverlay.showError(
      "An unexpected error occurred while processing your question.",
      "Processing Error"
    );
    return null;
  }
}



// -------------------------------
// Speak answer helper
// -------------------------------
async function speakAnswer(text) {
  // Stop any current speech so answers don't overlap
  try {
    window.speechSynthesis.cancel();
  } catch (e) {
    console.warn("Speech cancel failed", e);
  }

  // get user language from storage (your code uses await chrome.storage.sync.get elsewhere)
  const { userLanguage } = await chrome.storage.sync.get("userLanguage");
  const lang = userLanguage || "en";

  const utter = new SpeechSynthesisUtterance(text);
  utter.lang = lang;
  utter.onend = () => {
    console.log("üîä Finished speaking the answer");
  };
  utter.onerror = (err) => {
    console.error("üîä Speech error:", err);
  };

  try {
    window.speechSynthesis.speak(utter);
  } catch (err) {
    console.error("üîä speak() failed:", err);
  }
}

// =======================================
// Helper: Handle Page Summarisation
// =======================================
async function handleSummarisePage() {
  const loadingId = 'summary_' + Date.now();

  try {
    console.log("üß† Starting summarisation...");
    window.voxmateOverlay.showLoading(
      "Reading page content and generating concise summary...",
      "Generating Summary",
      loadingId
    );

    const { userLanguage } = await chrome.storage.sync.get("userLanguage");
    const lang = userLanguage || "en";

    const text = document.body?.innerText || "";
    if (!text.trim()) {
      window.voxmateOverlay.removeLoading(loadingId);
      window.voxmateOverlay.showWarning(
        "No readable text found on this page to summarize.",
        "No Content"
      );
      return null;
    }

    return new Promise((resolve) => {
      chrome.runtime.sendMessage(
        { action: "run_summarizer", text, lang },
        (response) => {
          if (chrome.runtime.lastError) {
            console.error("‚ùå Summariser error:", chrome.runtime.lastError.message);
            window.voxmateOverlay.removeLoading(loadingId);
            window.voxmateOverlay.showError(
              "Summarization service is currently unavailable.",
              "Service Error"
            );
            resolve(null);
            return;
          }

          if (!response?.success) {
            console.warn("‚ö†Ô∏è Summarisation failed:", response?.reason || response?.error);
            window.voxmateOverlay.removeLoading(loadingId);
            window.voxmateOverlay.showError(
              "Could not generate summary at this time.",
              "Summary Failed"
            );
            resolve(null);
            return;
          }

          const summary = response.summary?.trim() || "No summary could be generated from this page.";
          console.log("üìù Summary received:", summary);

          window.voxmateOverlay.removeLoading(loadingId);
          window.voxmateOverlay.showInfo(summary, "Page Summary");
          resolve(summary);
        }
      );
    });
  } catch (err) {
    console.error("‚ùå Error in handleSummarisePage:", err);
    window.voxmateOverlay.removeLoading(loadingId);
    window.voxmateOverlay.showError(
      "An unexpected error occurred while summarizing.",
      "Error"
    );
    return null;
  }
}

